{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "c_in: int = 20 # Number of input channels\n",
    "\n",
    "seq_len: int = 128 # Length of input sequences\n",
    "\n",
    "target_window: int = 96 # Length of prediction window, abhÃ¤ngig von config\n",
    "\n",
    "prediction length = 96 oder auch target window -> das was predicted werden soll!\n",
    "\n",
    "model uses huber loss for train and validation, test loss remains MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    random_seed=1\n",
    "    is_training=1\n",
    "    model_id='exchange'\n",
    "    model='JTFT'\n",
    "    data='custom'\n",
    "    root_path='./dataset/exchange_rate'\n",
    "    data_path='exchange_rate.csv'\n",
    "    features='M'\n",
    "    target='OT'\n",
    "    freq='h'\n",
    "    checkpoints='./checkpoints/'\n",
    "    seq_len=128\n",
    "    label_len=1\n",
    "    pred_len=96\n",
    "    fc_dropout=0.3\n",
    "    head_dropout=0.3\n",
    "    patch_len=4\n",
    "    stride=2\n",
    "    padding_patch='end'\n",
    "    revin=1\n",
    "    affine=0\n",
    "    subtract_last=0\n",
    "    decomposition=2\n",
    "    kernel_size=25\n",
    "    individual=0\n",
    "    embed_type=0\n",
    "    enc_in=8\n",
    "    dec_in=7\n",
    "    c_out=7\n",
    "    d_model=8\n",
    "    n_heads=2\n",
    "    e_layers=3\n",
    "    d_layers=1\n",
    "    d_ff=12\n",
    "    moving_avg=25\n",
    "    factor=1\n",
    "    distil=True\n",
    "    dropout=0.3\n",
    "    embed='timeF'\n",
    "    activation='gelu'\n",
    "    output_attention=False\n",
    "    do_predict=False\n",
    "    num_workers=2\n",
    "    itr=1\n",
    "    train_epochs=100\n",
    "    batch_size=64\n",
    "    patience=10\n",
    "    learning_rate=0.001\n",
    "    des='Exp'\n",
    "    loss='mse'\n",
    "    lradj='constant'\n",
    "    pct_start=0.3\n",
    "    use_amp=False\n",
    "    use_gpu=False\n",
    "    gpu=0\n",
    "    use_multi_gpu=False\n",
    "    devices='0,1,2,3'\n",
    "    est_flop=False\n",
    "    n_freq=16\n",
    "    n_concat_td=32\n",
    "    d_compress_max=1\n",
    "    e_layers_tfi=1\n",
    "    min_epochs=1\n",
    "    mod_scal_tfi=0.5\n",
    "    ini_with_low_freq=False\n",
    "    use_mark=False\n",
    "    resume_after_epo=0\n",
    "    sep_time_freq=False\n",
    "    use_huber_loss=True\n",
    "    huber_delta=1.0\n",
    "    b_not_compile=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils_eeg.tuh_eeg_utils import tuh_eeg_load_data_with_annotations, tuh_eeg_apply_TUH_bipolar_montage\n",
    "from utils_eeg.data_loader import DataLoader as EEGDataLoader\n",
    "\n",
    "\n",
    "PATH_TRAINING = \"/home/Bachelor-Thesis-JLB/TUH_EEG_SEIZ/edf/train\"\n",
    "PATH_TEST = \"/home/Bachelor-Thesis-JLB/TUH_EEG_SEIZ/edf/dev\"\n",
    "MONTAGE_ALL = [ # Montage that is included in all EEG Recordings\n",
    "    'FP1-F7', \n",
    "    'F7-T3', \n",
    "    'T3-T5', \n",
    "    'T5-O1', \n",
    "    'FP2-F8', \n",
    "    'F8-T4', \n",
    "    'T4-T6', \n",
    "    'T6-O2',\n",
    "    'T3-C3', \n",
    "    'C3-CZ', \n",
    "    'CZ-C4', \n",
    "    'C4-T4',\n",
    "    'FP1-F3', \n",
    "    'F3-C3', \n",
    "    'C3-P3', \n",
    "    'P3-O1', \n",
    "    'FP2-F4', \n",
    "    'F4-C4', \n",
    "    'C4-P4', \n",
    "    'P4-O2'\n",
    "] # len 20\n",
    "\n",
    "\n",
    "config_dataset = {\n",
    "    \"extensions\": [\".edf\", \".csv_bi\"],\n",
    "    \"l_freq\": 0.5,\n",
    "    \"h_freq\": 50,\n",
    "    \"resample_freq\": 50,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_eeg_data(file_path):\n",
    "    raw = tuh_eeg_load_data_with_annotations(edf_file=file_path[0], annotations_csv_file=file_path[1])\n",
    "\n",
    "    # apply bipolar montage\n",
    "    raw = tuh_eeg_apply_TUH_bipolar_montage(raw, file_path[0], only_return_bipolar=True)\n",
    "\n",
    "    # only select channels that are included in all recordings\n",
    "    raw = raw.pick(MONTAGE_ALL)\n",
    "\n",
    "    # filter data\n",
    "    raw = raw.filter(l_freq=config_dataset[\"l_freq\"], h_freq=config_dataset[\"h_freq\"], fir_design='firwin', method='fir', verbose=False)\n",
    "\n",
    "    # resample data\n",
    "    raw = raw.resample(config_dataset[\"resample_freq\"], npad='auto', verbose=False)\n",
    "\n",
    "    #  further processing\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "\n",
    "def eeg_data_generator(file_paths, sequence_length, batch_size, pred_len, preprocess_func):\n",
    "    while True:\n",
    "        for file_index, file_path in enumerate(file_paths):\n",
    "            print(f\"File: {file_index:>10} of {len(file_paths)}\")\n",
    "            try:\n",
    "                raw = preprocess_func(file_path)\n",
    "            except ValueError as e:\n",
    "                print(\"ERROR: \", e)\n",
    "                print(\"Loading next file\")\n",
    "                continue\n",
    "            # except e:\n",
    "            #     print(\"ERROR: \", e)\n",
    "            #     print(\"Loading next file\")\n",
    "            #     continue\n",
    "\n",
    "            data_array = raw.get_data()\n",
    "\n",
    "\n",
    "            for start_idx in range(0, len(raw), sequence_length + 1):\n",
    "                if start_idx + sequence_length > len(raw):\n",
    "                    break\n",
    "                data_x, time_x = raw[:, start_idx:start_idx + sequence_length]\n",
    "                data_y, time_y = raw[:, start_idx + sequence_length:start_idx + sequence_length + pred_len]\n",
    "\n",
    "                yield data_x, time_x, data_y, time_y\n",
    "\n",
    "\n",
    "def calc_dataset_length_tuh(file_paths, sequence_length, pred_length, batch_size):\n",
    "    dataset_length = 0\n",
    "    print(\"Calculating dataset length\")\n",
    "    for idx, file_path in enumerate(file_paths):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Processed: {idx:>10} files | current dataset length: {int(dataset_length):>10}\", end=\"\\r\")\n",
    "            \n",
    "\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(file_path[0], preload=False, verbose=False)\n",
    "\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(\"ERROR: \", e)\n",
    "            print(\"Loading next file\")\n",
    "            continue\n",
    "\n",
    "        dataset_length += ((len(raw) / raw.info[\"sfreq\"]) * config_dataset[\"resample_freq\"])\\\n",
    "              // (sequence_length + pred_length + 1)\n",
    "        \n",
    "\n",
    "    print(f\"Total files processed: {idx:>10} | Dataset length: {int(dataset_length):>10}\")\n",
    "    return int(dataset_length)\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_path, \n",
    "                 preprocess_func, \n",
    "                 data_extensions=['.edf', '.csv_bi'], \n",
    "                 batch_size=16,\n",
    "                 sequence_length=128,\n",
    "                 pred_length=96):\n",
    "        data_loader = EEGDataLoader(root_path=data_path, extensions=data_extensions)\n",
    "        self.file_paths = data_loader.file_tuples\n",
    "        self.preprocess_func = preprocess_func\n",
    "\n",
    "        self.generator = eeg_data_generator(file_paths=self.file_paths, \n",
    "                                            batch_size=batch_size, \n",
    "                                            preprocess_func=preprocess_func, \n",
    "                                            sequence_length=sequence_length,\n",
    "                                            pred_len=pred_length)\n",
    "        \n",
    "        # calculate dataset length\n",
    "        self.dataset_length = calc_dataset_length_tuh(file_paths=self.file_paths, \n",
    "                                                       batch_size=batch_size, \n",
    "                                                       sequence_length=sequence_length, \n",
    "                                                       pred_length=pred_length)\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.file_paths)\n",
    "        return self.dataset_length\n",
    "\n",
    "    def __getitem__(self, idx=None):\n",
    "        return next(self.generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataset length\n",
      "Total files processed:       4663 | Dataset length:     72587111\n"
     ]
    }
   ],
   "source": [
    "dataset_eeg = EEGDataset(data_path=PATH_TRAINING, \n",
    "                         preprocess_func=preprocess_eeg_data, \n",
    "                         batch_size=16,\n",
    "                         sequence_length=128,\n",
    "                         pred_length=96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "725871"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i, data in enumerate(dataset_eeg):\n",
    "    print(i)\n",
    "    print(data[0].shape, data[1].shape, data[2].shape, data[3].shape)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 128),\n",
       " array([2.58, 2.6 , 2.62, 2.64, 2.66, 2.68, 2.7 , 2.72, 2.74, 2.76, 2.78,\n",
       "        2.8 , 2.82, 2.84, 2.86, 2.88, 2.9 , 2.92, 2.94, 2.96, 2.98, 3.  ,\n",
       "        3.02, 3.04, 3.06, 3.08, 3.1 , 3.12, 3.14, 3.16, 3.18, 3.2 , 3.22,\n",
       "        3.24, 3.26, 3.28, 3.3 , 3.32, 3.34, 3.36, 3.38, 3.4 , 3.42, 3.44,\n",
       "        3.46, 3.48, 3.5 , 3.52, 3.54, 3.56, 3.58, 3.6 , 3.62, 3.64, 3.66,\n",
       "        3.68, 3.7 , 3.72, 3.74, 3.76, 3.78, 3.8 , 3.82, 3.84, 3.86, 3.88,\n",
       "        3.9 , 3.92, 3.94, 3.96, 3.98, 4.  , 4.02, 4.04, 4.06, 4.08, 4.1 ,\n",
       "        4.12, 4.14, 4.16, 4.18, 4.2 , 4.22, 4.24, 4.26, 4.28, 4.3 , 4.32,\n",
       "        4.34, 4.36, 4.38, 4.4 , 4.42, 4.44, 4.46, 4.48, 4.5 , 4.52, 4.54,\n",
       "        4.56, 4.58, 4.6 , 4.62, 4.64, 4.66, 4.68, 4.7 , 4.72, 4.74, 4.76,\n",
       "        4.78, 4.8 , 4.82, 4.84, 4.86, 4.88, 4.9 , 4.92, 4.94, 4.96, 4.98,\n",
       "        5.  , 5.02, 5.04, 5.06, 5.08, 5.1 , 5.12]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape, data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_eeg = EEGDataLoader(root_path=PATH_TRAINING, extensions=['.edf', '.csv_bi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/Bachelor-Thesis-JLB/TUH_EEG_SEIZ/edf/train/aaaaajvs/s002_2011_03_09/03_tcp_ar_a/aaaaajvs_s002_t005.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_edf(data_loader_eeg.file_tuples[0][0], preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "153856"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "153856"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "30050.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(raw.info[\"sfreq\"], len(raw))\n",
    "\n",
    "display(len(raw.get_data()[0]))\n",
    "\n",
    "display((len(raw) / raw.info[\"sfreq\"]) * config_dataset[\"resample_freq\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.exp_main_JTFT import Exp_Main_JTFT\n",
    "import torch\n",
    "\n",
    "Exp = Exp_Main_JTFT\n",
    "\n",
    "setting_base = '{}_{}_sl{}_pl{}_strd{}_freq{}_dm{}_nh{}_el{}_df{}'.format(\n",
    "        args.model_id,\n",
    "        args.model,\n",
    "        args.seq_len,\n",
    "        args.pred_len,\n",
    "        args.stride,\n",
    "        args.n_freq,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        args.d_ff)\n",
    "\n",
    "if args.is_training:\n",
    "    for ii in range(args.itr):\n",
    "        setting = setting_base+'_{}{}'.format(args.des,ii)\n",
    "        exp = Exp(args)  # set experiments\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(''.join(setting)))\n",
    "        exp.train(setting)\n",
    "        print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(''.join(setting)))\n",
    "        exp.test(setting)\n",
    "        \n",
    "        if args.do_predict:\n",
    "            print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(''.join(setting)))\n",
    "            exp.predict(setting, True)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "else:\n",
    "    ii = 0 .format(args.des,ii)\n",
    "    \n",
    "    exp = Exp(args)  # set experiments\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(''.join(setting)))\n",
    "    exp.test(setting, test=1)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_eeg.data_loader import DataLoader as EEG_DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from utils_eeg.tuh_eeg_utils import  tuh_eeg_load_data_with_annotations, tuh_eeg_apply_TUH_bipolar_montage\n",
    "\n",
    "\n",
    "PATH_TRAINING = \"/home/Bachelor-Thesis-JLB/TUH_EEG_SEIZ/edf/train\"\n",
    "PATH_TEST = \"/home/Bachelor-Thesis-JLB/TUH_EEG_SEIZ/edf/dev\"\n",
    "MONTAGE_ALL = [ # Montage that is included in all EEG Recordings\n",
    "    'FP1-F7', \n",
    "    'F7-T3', \n",
    "    'T3-T5', \n",
    "    'T5-O1', \n",
    "    'FP2-F8', \n",
    "    'F8-T4', \n",
    "    'T4-T6', \n",
    "    'T6-O2',\n",
    "    'T3-C3', \n",
    "    'C3-CZ', \n",
    "    'CZ-C4', \n",
    "    'C4-T4',\n",
    "    'FP1-F3', \n",
    "    'F3-C3', \n",
    "    'C3-P3', \n",
    "    'P3-O1', \n",
    "    'FP2-F4', \n",
    "    'F4-C4', \n",
    "    'C4-P4', \n",
    "    'P4-O2'\n",
    "]\n",
    "\n",
    "\n",
    "config_dataset = {\n",
    "    \"extensions\": [\".edf\", \".csv_bi\"],\n",
    "    \"l_freq\": 0.5,\n",
    "    \"h_freq\": 50,\n",
    "    \"resample_freq\": 50,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class EEG_Dataset(Dataset):\n",
    "    def __init__(self, data_path, args, flag='train'):\n",
    "\n",
    "        assert flag in ['train', 'test', 'pred'], \"flag should be 'train', 'test' or 'pred'\"\n",
    "\n",
    "\n",
    "        # args\n",
    "        if flag == 'test':\n",
    "            self.seq_len = args.seq_len\n",
    "            self.shuffle_flag = False\n",
    "            self.batch_size = args.batch_size\n",
    "            self.freq = args.freq\n",
    "        elif flag == 'pred':\n",
    "            self.shuffle_flag = False\n",
    "            self.drop_last = False\n",
    "            self.batch_size = 1\n",
    "            self.freq = args.freq\n",
    "\n",
    "        else: # train\n",
    "            self.batch_size = args.batch_size\n",
    "            self.freq = args.freq\n",
    "            self.shuffle_flag = True\n",
    "            self.drop_last = True\n",
    "\n",
    "        # data\n",
    "        self.data_path = data_path\n",
    "        self.data_loader = EEG_DataLoader(self.data_path, extensions=config_dataset['extensions'], shuffle=self.shuffle_flag)\n",
    "\n",
    "\n",
    "        if self.shuffle_flag:\n",
    "            self.current_eeg_file = self.data_loader.get_next_shuffled()\n",
    "        else:\n",
    "            self.current_eeg_file = self.data_loader.get_next()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def load_current_eeg(self):\n",
    "        self.current_eeg_data = tuh_eeg_load_data_with_annotations(self.current_eeg_file[0], self.current_eeg_file[1])\n",
    "\n",
    "        try:\n",
    "            self.current_eeg_data = tuh_eeg_apply_TUH_bipolar_montage(self.current_eeg_data, self.current_eeg_file[0], onyl_return_bipolar=True)\n",
    "    \t\n",
    "        except ValueError as e:\n",
    "            print(\"ERROR: \", e)\n",
    "            if self.shuffle_flag:\n",
    "                self.current_eeg_file = self.data_loader.get_next_shuffled()\n",
    "            else:\n",
    "                self.current_eeg_data = self.data_loader.get_next()\n",
    "            \n",
    "            self.load_current_eeg()\n",
    "            return\n",
    "        \n",
    "        # create filter\n",
    "        self.current_eeg_data = self.current_eeg_data.copy().filter(config_dataset[\"l_freq\"], config_dataset['h_freq'], fir_design='firwin', method='fir', verbose=False)\n",
    "\n",
    "        # resample data\n",
    "        self.current_eeg_data = self.current_eeg_data.resample(config_dataset[\"resample_freq\"], npad=\"auto\")\n",
    "\n",
    "        # epoch the data\n",
    "        epochs, labels = tuh_eeg_create_epochs_with_labels()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_loader.file_tuples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data_loader\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_compress in mapped transformer 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# model JTFT\n",
    "from models.JTFT import Model as JTFT_Model\n",
    "\n",
    "model = JTFT_Model(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
